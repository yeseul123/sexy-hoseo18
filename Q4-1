



import tensorflow as tf
import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

w = tf.Variable(tf.random_uniform([1], -1.0, 1.0))
b = tf.Variable(tf.random_uniform([1], -1.0, 1.0))

x= tf.placeholder(tf.float32)
y = tf.placeholder(tf.float32)

model = w * x + b
cost = tf.reduce_mean(tf.square(model-y))
opt = tf.train.GradientDescentOptimizer(learning_rate=0.05)

train = opt.minimize(cost)

train_tot = 100
sess = tf.Session()
sess.run(tf.global_variables_initializer())

x_tr = [1]
y_tr = [1]

for i in range(train_tot):
    error, _ = sess.run([cost,train], feed_dict={x: x_tr, y : y_tr})
    print(i, 'error = %.3f' % error, 'w = %.3f' % sess.run(w), 'b = %.3f ' % sess.run(b))

test = 100
guess = sess.run(model, feed_dict={x: test})
print('\ntest =', test, 'guess = %.3f' % guess)
